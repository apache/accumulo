<?xml version="1.0" encoding="UTF-8"?>
<!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional 
  information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except 
  in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to 
  in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See 
  the License for the specific language governing permissions and limitations under the License. -->
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <!-- Put your site-specific accumulo configurations here. The available configuration values along with their defaults are documented in docs/config.html Unless 
    you are simply testing at your workstation, you will most definitely need to change the three entries below. -->

  <property>
    <name>instance.zookeeper.host</name>
    <value>localhost:2181</value>
    <description>comma separated list of zookeeper servers</description>
  </property>

  <property>
    <name>logger.dir.walog</name>
    <value>walogs</value>
    <description>The directory used to store write-ahead logs on the local filesystem. It is possible to specify a comma-separated list of directories.
    </description>
  </property>

  <property>
    <name>instance.secret</name>
    <value>DEFAULT</value>
    <description>A secret unique to a given instance that all servers must know in order to communicate with one another.
      Change it before initialization. To change it later use ./bin/accumulo org.apache.accumulo.server.util.ChangeSecret --old [oldpasswd] --new [newpasswd],
      and then update this file.
    </description>
  </property>

  <property>
    <name>tserver.memory.maps.max</name>
    <value>80M</value>
  </property>

  <property>
    <name>tserver.cache.data.size</name>
    <value>7M</value>
  </property>

  <property>
    <name>tserver.cache.index.size</name>
    <value>20M</value>
  </property>

  <property>
    <name>trace.password</name>
    <!-- change this to the root user's password, and/or change the user below -->
    <value>secret</value>
  </property>

  <property>
    <name>trace.user</name>
    <value>root</value>
  </property>

  <property>
    <name>tserver.sort.buffer.size</name>
    <value>50M</value>
  </property>

  <property>
    <name>tserver.walog.max.size</name>
    <value>100M</value>
  </property>

  <property>
    <name>general.classpaths</name>
    <!--
       Add the following for hadoop-2.0
       $HADOOP_PREFIX/share/hadoop/common/.*.jar,
       $HADOOP_PREFIX/share/hadoop/common/lib/.*.jar,
       $HADOOP_PREFIX/share/hadoop/hdfs/.*.jar,
       $HADOOP_PREFIX/share/hadoop/mapreduce/.*.jar,
       $HADOOP_PREFIX/share/hadoop/yarn/.*.jar,
    -->
    <value>
      $ACCUMULO_HOME/server/target/classes/,
      $ACCUMULO_HOME/core/target/classes/,
      $ACCUMULO_HOME/start/target/classes/,
      $ACCUMULO_HOME/examples/target/classes/,
      $ACCUMULO_HOME/lib/[^.].$ACCUMULO_VERSION.jar,
      $ACCUMULO_HOME/lib/[^.].*.jar,
      $ZOOKEEPER_HOME/zookeeper[^.].*.jar,
      $HADOOP_HOME/conf,
      $HADOOP_HOME/[^.].*.jar,
      $HADOOP_HOME/lib/[^.].*.jar,
    </value>
    <description>Classpaths that accumulo checks for updates and class files.
      When using the Security Manager, please remove the ".../target/classes/" values.
    </description>
  </property>

  <!-- VFS ClassLoader Settings -->
  
  <!--
  At a minimum the general.vfs.classpath property must be set. After this is set in the configuration, the bin/bootstrap_hdfs.sh can be
  run to move the jars into the required locations. All other properties are optional. This example demonstrates using hdfs, other
  protocols supported by the Apache Commons VFS software can be used but are not demonstrated here. If the accumulo-site.xml changes
  after initial configuration, you will want to copy the file to all of the slave hosts. 
  -->
  <property>
    <name>general.vfs.classpaths</name>
    <value>hdfs://localhost:8020/accumulo/system-classpath</value>
    <description>Configuration for a system level vfs classloader.  Accumulo jars can be configured here and loaded out of HDFS.</description>
  </property>

  <property>
    <name>general.vfs.cache.dir</name>
    <value>/tmp</value>
    <description>Directory to use for the vfs cache. The cache will keep a soft reference to all of the classes loaded in the VM. 
    This should be on local disk on each node with sufficient space. It defaults to /tmp and will use a directory with the 
    format "accumulo-vfs-cache-" + System.getProperty("user.name", "nouser")
    </description>
  </property>

  <!--
  Properties in this category define a classpath for a named context. These properties start with the category prefix, followed by a context name.
  The value is a comma seperated list of URIs. Supports full regex on filename alone. For example 
  general.vfs.context.classpath.cx1=hdfs://nn1:9902/mylibdir/*.jar.  You can enable post delegation for a context, which will load classes from 
  the context first instead of the parent first.  Do this by setting general.vfs.context.classpath.<name>.delegation=post, where <name> 
  is your context name.  If delegation is not specified, it defaults to loading from parent classloader first.
  -->

  <property>
    <name>general.vfs.context.classpath.application1</name>
    <value>hdfs://localhost:8020/application1/classpath/*.jar</value>
    <description>classpath for the application1 context</description>
  </property>

  <property>
    <name>general.vfs.context.classpath.application1.delegation=post</name>
    <value>hdfs://localhost:8020/application1/classpath/*.jar</value>
    <description>classpath for the application1 context, but the classloader parent delegation model is inverted to prefer the jars/classes in this directory</description>
  </property>

  <property>
    <name>general.vfs.context.classpath.application2</name>
    <value>hdfs://localhost:8020/application1/classpath/*.jar,hdfs://localhost:8020/application2/classpath/*.jar</value>
    <description>classpath for the application2 context, includes all of the jars in app1 context</description>
  </property>
  
  <!--
  Once classpath context are configured, tables can be configured in the shell to use them via the table.classpath.context property.
  For example, all of the tables related to application1 would have the context.classpath property set to 'application1'. 
  -->

</configuration>
